{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. It works by finding the hyperplane that best separates the data into different classes. The main goal of SVM is to maximize the margin between the data points of different classes. SVM can handle both linear and non-linear data by using kernel functions to transform the data into higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) Terminology\n",
    "- **Hyperplane:** A decision boundary separating different classes in feature space, represented by the equation $$ wx + b = 0 $$ in linear classification.\n",
    "- **Support Vectors:** The closest data points to the hyperplane, crucial for determining the hyperplane and margin in SVM.\n",
    "- **Margin:** The distance between the hyperplane and the support vectors. SVM aims to maximize this margin for better classification performance.\n",
    "- **Kernel:** A function that maps data to a higher-dimensional space, enabling SVM to handle non-linearly separable data.\n",
    "- **Hard Margin:** A maximum-margin hyperplane that perfectly separates the data without misclassifications.\n",
    "- **Soft Margin:** Allows some misclassifications by introducing slack variables, balancing margin maximization and misclassification penalties when data is not perfectly separable.\n",
    "- **C:** A regularization term balancing margin maximization and misclassification penalties. A higher C value enforces a stricter penalty for misclassifications.\n",
    "- **Hinge Loss:** A loss function penalizing misclassified points or margin violations, combined with regularization in SVM.\n",
    "- **Dual Problem:** Involves solving for Lagrange multipliers associated with support vectors, facilitating the kernel trick and efficient computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Support Vector Machine Algorithm Work?\n",
    "The key idea behind the SVM algorithm is to find the hyperplane that best separates two classes by maximizing the margin between them. This margin is the distance from the hyperplane to the nearest data points (support vectors) on each side.\n",
    "![Image](https://github.com/user-attachments/assets/aed02bf5-ac1b-4bc2-b63f-d73805913301)\n",
    "The best hyperplane, also known as the “hard margin,” is the one that maximizes the distance between the hyperplane and the nearest data points from both classes. This ensures a clear separation between the classes. So, from the above figure, we choose L2 as hard margin.\n",
    "\n",
    "Let’s consider a scenario like shown below:\n",
    "![Image](https://github.com/user-attachments/assets/63b39000-3159-44d7-bd9a-e223b0c3af24)\n",
    "\n",
    "Here, we have one blue ball in the boundary of the red ball.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/67e02c1a-f843-4557-9bf9-cee3f795ce2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/8ed55514-6920-4610-b5e1-6db64169c38b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/6c62b8fc-ec80-4219-b767-16b815abf6ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Kernel Function\n",
    "A kernel function is a mathematical function used in Support Vector Machines (SVM) to transform the input data into a higher-dimensional space. This transformation allows SVM to handle non-linearly separable data by finding a linear hyperplane in the transformed space. Common kernel functions include:\n",
    "\n",
    "- **Linear Kernel:** $$ K(x_i, x_j) = x_i \\cdot x_j $$\n",
    "- **Polynomial Kernel:** $$ K(x_i, x_j) = (\\gamma x_i \\cdot x_j + r)^d $$\n",
    "- **Radial Basis Function (RBF) Kernel:** $$ K(x_i, x_j) = \\exp(-\\gamma \\| x_i - x_j \\|^2) $$\n",
    "- **Sigmoid Kernel:** $$ K(x_i, x_j) = \\tanh(\\gamma x_i \\cdot x_j + r) $$\n",
    "\n",
    "Where:\n",
    "- \\( x_i \\) and \\( x_j \\) are input vectors.\n",
    "- \\( \\gamma \\) is a parameter that defines the influence of a single training example.\n",
    "- \\( r \\) is a constant term.\n",
    "- \\( d \\) is the degree of the polynomial.\n",
    "\n",
    "The choice of kernel function and its parameters can significantly impact the performance of the SVM model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/18d0d11b-3619-400a-81e1-018b973bebb6)\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/43217061-a2a8-494d-873e-29d306a1bbf5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
