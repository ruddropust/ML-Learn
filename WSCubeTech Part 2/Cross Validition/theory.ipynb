{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "**Cross-validation** is a statistical method used to estimate the skill of machine learning models. It is commonly used to assess how the results of a statistical analysis will generalize to an independent data set. The goal of cross-validation is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and give an insight on how the model will generalize to an independent dataset.\n",
    "\n",
    "The basic form of cross-validation is k-fold cross-validation. Here is how it works:\n",
    "\n",
    "1. **Split the dataset into k subsets**: The data is divided into k equally (or nearly equally) sized subsets.\n",
    "2. **For each subset**:\n",
    "    - Use the subset as the validation set.\n",
    "    - Use the remaining k-1 subsets as the training set.\n",
    "    - Train the model on the training set and evaluate it on the validation set.\n",
    "3. **Aggregate the results**: The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.\n",
    "\n",
    "Other forms of cross-validation include:\n",
    "- **Leave-One-Out Cross-Validation (LOOCV)**: A special case of k-fold cross-validation where k is equal to the number of data points in the dataset.\n",
    "- **Stratified k-Fold Cross-Validation**: Ensures that each fold is representative of all classes in the data, which is particularly useful for imbalanced datasets.\n",
    "- **Time Series Cross-Validation**: Used for time series data where the order of data points matters.\n",
    "\n",
    "Cross-validation helps in selecting the best model and tuning hyperparameters by providing a more accurate estimate of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``It's a technique for validiting the model efficiency by training it on the subset of input data and testing on previously unseen subset of the input data``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/973db0e2-6d02-43e9-a2d2-bc72659bfb8f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CV](https://miro.medium.com/v2/resize:fit:720/format:webp/1*KgFHBaLJQGY-VYcKA3LFLg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/4dd081b4-1918-4535-9012-3b9cc479aea1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **K-fold cross-validation** \n",
    "**K-fold cross-validation** is a technique to evaluate the performance of a model by dividing the dataset into k equal subsets. The model is trained on k-1 subsets and validated on the remaining subset, repeated k times to ensure robustness.\n",
    "\n",
    "``It's not suite for imbalence dataset`` if k=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![K-fold](https://i0.wp.com/spotintelligence.com/wp-content/uploads/2023/07/k-fold-cross-validation-1024x576.webp?resize=1024%2C576&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![K-fold](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/37094K-fold-cross-vaslidation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stratified k-Fold Cross-Validation**\n",
    "\n",
    "Stratified k-Fold Cross-Validation is a variation of k-fold cross-validation that ensures each fold is representative of all classes in the data. This is particularly useful for imbalanced datasets where some classes are underrepresented. The process is as follows:\n",
    "\n",
    "1. **Split the dataset into k subsets**: The data is divided into k equally (or nearly equally) sized subsets, ensuring that each subset has the same proportion of each class as the original dataset.\n",
    "2. **For each subset**:\n",
    "    - Use the subset as the validation set.\n",
    "    - Use the remaining k-1 subsets as the training set.\n",
    "    - Train the model on the training set and evaluate it on the validation set.\n",
    "3. **Aggregate the results**: The performance measure reported by stratified k-fold cross-validation is then the average of the values computed in the loop.\n",
    "\n",
    "This method helps in providing a more accurate estimate of model performance, especially when dealing with imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use\n",
    "- When working with datasets that have an unbalanced distribution of classes.\n",
    "- When random shuffling and splitting the data is not sufficient.\n",
    "- When you want to have a correct distribution of data in each fold.\n",
    "\n",
    "## Benefits\n",
    "- Ensures that each fold of the dataset contains approximately the same percentage of samples of each class as the complete set.\n",
    "- Mitigates bias and improves overall performance.\n",
    "- Provides a more robust and reliable estimate of model performance.\n",
    "\n",
    "## How It Works\n",
    "- Preserves the original class distribution in each fold.\n",
    "- Guarantees that your model is trained and tested on a representative sample of each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dataaspirant.com/wp-content/uploads/2020/12/8-Stratified-K-Fold-Cross-Validation-768x516.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOCV (Leave One Out Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dataaspirant.com/wp-content/uploads/2023/10/3-3-768x811.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "Leave-One-Out Cross-Validation (LOOCV) is a resampling procedure used to evaluate machine learning models on a limited data sample. The method has a simple yet meticulous approach, carefully attending to each data point and assessing the model’s predictive capability with precision.\n",
    "\n",
    "### Step 1: Data Preparation\n",
    "\n",
    "- **Dataset Isolation**: Isolate your dataset, ensuring it is cleansed and pre-processed, ready for model evaluation.\n",
    "- **Data Segregation**: Identify individual data points; each will serve as a validation set in its turn.\n",
    "\n",
    "### Step 2: Iterative Model Training and Validation\n",
    "\n",
    "1. **Iteration Initiation**: Begin with the first data point as the validation set and the remainder as the training set.\n",
    "2. **Model Training**: Employ the training set to train your model, fine-tuning as per algorithm-specific parameters.\n",
    "3. **Validation Assessment**: Utilize the isolated data point to validate the model, recording the error metric or model prediction.\n",
    "4. **Iteration Continuation**: Progress to the next data point, reallocating the training and validation sets accordingly, and repeat the training and validation process.\n",
    "\n",
    "### Step 3: Error Aggregation\n",
    "\n",
    "- **Error Calculation**: For each iteration, compute and store the error metric (such as Mean Squared Error for regression or Accuracy for classification).\n",
    "- **Aggregate Error**: Once all iterations are complete, average the recorded error metrics to procure an overall performance estimate.\n",
    "\n",
    "### Step 4: Model Evaluation\n",
    "\n",
    "- **Performance Insight**: The aggregated error provides insight into the model’s predictive capability and generalization to unseen data.\n",
    "- **Model Comparison**: Use the aggregated error to compare the effectiveness of different models or model parameters.\n",
    "\n",
    "### Step 5: Final Model Training\n",
    "\n",
    "- **Comprehensive Training**: Once model selection and tuning are complete, utilize the entire dataset to train the final model.\n",
    "- **Real-world Application**: Implement the fully trained model to make predictions on new, unseen data.\n",
    "\n",
    "### Step 6: Review and Reflection\n",
    "\n",
    "- **Model Review**: Reflect on the model’s performance and consider whether alternative approaches or additional tuning is warranted.\n",
    "- **Practical Implication**: Consider the practical implications of the model, ensuring it aligns with the problem context and project objectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-p-out cross validation\n",
    "\"Leave-p-out cross validation\"refers to a cross-validation technique where a subset of \"p\" observations from a dataset are used as the validation set, while the remaining data is used for training, and this process is repeated by iterating through every possible combination of \"p\" observations as the validation set, essentially testing the model against different \"p\" sized validation sets across the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dataaspirant.com/wp-content/uploads/2023/10/1-3-768x467.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
